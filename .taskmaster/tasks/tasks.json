{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Initialize Project Structure and Dependencies",
        "description": "Set up the Python project with proper directory structure, virtual environment, and install all required dependencies including pandas, numpy, plotly, anthropic, pydantic, python-dotenv, and pytest.",
        "details": "Create the following directory structure:\n```\nproject-root/\n├── src/\n│   ├── __init__.py\n│   ├── data_processing/\n│   │   ├── __init__.py\n│   │   ├── ingestion.py\n│   │   └── validation.py\n│   ├── metrics/\n│   │   ├── __init__.py\n│   │   ├── basic_metrics.py\n│   │   ├── time_metrics.py\n│   │   └── anomaly_metrics.py\n│   ├── analysis/\n│   │   └── __init__.py\n│   ├── visualization/\n│   │   └── __init__.py\n│   └── reporting/\n│       └── __init__.py\n├── tests/\n│   ├── __init__.py\n│   ├── test_data_processing/\n│   ├── test_metrics/\n│   └── fixtures/\n├── requirements.txt\n├── .env.example\n├── .gitignore\n└── README.md\n```\n\nCreate requirements.txt:\n```\npandas==2.2.0\nnumpy==1.26.3\nplotly==5.18.0\nanthropicpython-dotenv==1.0.0\npydantic==2.5.3\npytest==7.4.4\npytest-cov==4.1.0\n```\n\nSet up virtual environment:\n```bash\npython3.13 -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\npip install -r requirements.txt\n```",
        "testStrategy": "Verify project structure by running: `python -c \"import pandas, numpy, plotly, anthropic, pydantic, dotenv, pytest\"` to ensure all dependencies are installed. Create a simple test file that imports from each module directory to verify proper Python package structure.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "Implement Data Ingestion and Validation Module",
        "description": "Create the data processing module with CSV ingestion capabilities using pandas and data validation using pydantic models. Handle required columns, data types, and implement robust error handling.",
        "details": "In `src/data_processing/validation.py`:\n```python\nfrom pydantic import BaseModel, validator\nfrom typing import Optional\nimport pandas as pd\n\nclass MinerDataSchema(BaseModel):\n    class Config:\n        arbitrary_types_allowed = True\n    \n    seconds: pd.Series\n    mode_power: pd.Series\n    summary_wattage: pd.Series\n    temp_hash_board_max: pd.Series\n    psu_temp_max: pd.Series\n    outage: pd.Series\n    \n    @validator('seconds')\n    def validate_seconds(cls, v):\n        if v.dtype not in ['float64', 'int64']:\n            raise ValueError('seconds must be numeric')\n        return v\n```\n\nIn `src/data_processing/ingestion.py`:\n```python\nimport pandas as pd\nimport logging\nfrom pathlib import Path\nfrom typing import Dict, Any\n\nlogger = logging.getLogger(__name__)\n\nclass DataIngestion:\n    REQUIRED_COLUMNS = [\n        'miner.seconds',\n        'miner.mode.power',\n        'miner.summary.wattage',\n        'miner.temp.hash_board_max',\n        'miner.psu.temp_max',\n        'miner.outage'\n    ]\n    \n    def load_csv(self, filepath: Path) -> pd.DataFrame:\n        \"\"\"Load and validate CSV file.\"\"\"\n        try:\n            df = pd.read_csv(filepath)\n            self._validate_columns(df)\n            df = self._standardize_column_names(df)\n            df = self._convert_types(df)\n            return df\n        except Exception as e:\n            logger.error(f\"Failed to load CSV: {e}\")\n            raise\n    \n    def _validate_columns(self, df: pd.DataFrame) -> None:\n        missing = set(self.REQUIRED_COLUMNS) - set(df.columns)\n        if missing:\n            raise ValueError(f\"Missing required columns: {missing}\")\n    \n    def _standardize_column_names(self, df: pd.DataFrame) -> pd.DataFrame:\n        rename_map = {\n            'miner.seconds': 'seconds',\n            'miner.mode.power': 'mode_power',\n            'miner.summary.wattage': 'summary_wattage',\n            'miner.temp.hash_board_max': 'temp_hash_board_max',\n            'miner.psu.temp_max': 'psu_temp_max',\n            'miner.outage': 'outage'\n        }\n        return df.rename(columns=rename_map)\n    \n    def _convert_types(self, df: pd.DataFrame) -> pd.DataFrame:\n        df['seconds'] = pd.to_numeric(df['seconds'], errors='coerce')\n        df['mode_power'] = pd.to_numeric(df['mode_power'], errors='coerce')\n        df['summary_wattage'] = pd.to_numeric(df['summary_wattage'], errors='coerce')\n        df['outage'] = df['outage'].astype(bool)\n        return df\n```",
        "testStrategy": "Create unit tests in `tests/test_data_processing/test_ingestion.py` that verify:\n1. Successful loading of valid CSV files\n2. Proper error handling for missing columns\n3. Correct type conversions\n4. Handling of malformed data\n5. Create fixture CSV files with various edge cases (missing columns, wrong types, empty files)",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "Implement Data Preprocessing Pipeline",
        "description": "Create preprocessing functions to sort data chronologically, identify action time (t=0), handle NaN values, and prepare data for metric calculations.",
        "details": "In `src/data_processing/preprocessing.py`:\n```python\nimport pandas as pd\nimport numpy as np\nfrom typing import Dict, Tuple, Any\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass DataPreprocessor:\n    def __init__(self, df: pd.DataFrame):\n        self.df = df.copy()\n        self.action_index = None\n        self.metadata = {}\n    \n    def preprocess(self) -> Tuple[pd.DataFrame, Dict[str, Any]]:\n        \"\"\"Main preprocessing pipeline.\"\"\"\n        self._sort_by_time()\n        self._identify_action_point()\n        self._check_data_quality()\n        self._handle_nan_values()\n        return self.df, self.metadata\n    \n    def _sort_by_time(self) -> None:\n        \"\"\"Sort data chronologically by seconds column.\"\"\"\n        self.df = self.df.sort_values('seconds').reset_index(drop=True)\n        logger.info(f\"Sorted {len(self.df)} rows by time\")\n    \n    def _identify_action_point(self) -> None:\n        \"\"\"Find the index where seconds crosses from negative to non-negative.\"\"\"\n        # Find transition point\n        negative_mask = self.df['seconds'] < 0\n        if not negative_mask.any():\n            logger.warning(\"No pre-action data found (all times >= 0)\")\n            self.action_index = 0\n        elif negative_mask.all():\n            logger.warning(\"No post-action data found (all times < 0)\")\n            self.action_index = len(self.df) - 1\n        else:\n            # Find first non-negative index\n            self.action_index = (~negative_mask).idxmax()\n        \n        self.metadata['action_index'] = self.action_index\n        self.metadata['action_time'] = self.df.loc[self.action_index, 'seconds']\n    \n    def _check_data_quality(self) -> None:\n        \"\"\"Assess data quality and log warnings.\"\"\"\n        # Check for NaN values\n        nan_counts = self.df.isnull().sum()\n        for col, count in nan_counts.items():\n            if count > 0:\n                pct = (count / len(self.df)) * 100\n                logger.warning(f\"Column '{col}' has {count} NaN values ({pct:.1f}%)\")\n                self.metadata[f'{col}_nan_count'] = count\n        \n        # Check for data gaps\n        time_diffs = self.df['seconds'].diff()\n        max_gap = time_diffs.max()\n        if max_gap > 10:  # More than 10 second gap\n            logger.warning(f\"Large time gap detected: {max_gap:.1f} seconds\")\n            self.metadata['max_time_gap'] = max_gap\n    \n    def _handle_nan_values(self) -> None:\n        \"\"\"Strategy for handling NaN values in wattage.\"\"\"\n        # For wattage, we'll keep NaN as-is but flag segments\n        wattage_nan_mask = self.df['summary_wattage'].isna()\n        if wattage_nan_mask.any():\n            # Find continuous NaN segments\n            nan_segments = []\n            in_segment = False\n            start_idx = None\n            \n            for idx, is_nan in enumerate(wattage_nan_mask):\n                if is_nan and not in_segment:\n                    start_idx = idx\n                    in_segment = True\n                elif not is_nan and in_segment:\n                    nan_segments.append((start_idx, idx-1))\n                    in_segment = False\n            \n            if in_segment:\n                nan_segments.append((start_idx, len(self.df)-1))\n            \n            self.metadata['wattage_nan_segments'] = nan_segments\n    \n    def get_pre_action_data(self) -> pd.DataFrame:\n        \"\"\"Return data before action point.\"\"\"\n        return self.df[self.df['seconds'] < 0].copy()\n    \n    def get_post_action_data(self) -> pd.DataFrame:\n        \"\"\"Return data at and after action point.\"\"\"\n        return self.df[self.df['seconds'] >= 0].copy()\n```",
        "testStrategy": "Create comprehensive tests in `tests/test_data_processing/test_preprocessing.py`:\n1. Test sorting with unsorted data\n2. Test action point identification with various scenarios (no pre-data, no post-data, normal)\n3. Test NaN handling and segment identification\n4. Test data quality checks and metadata generation\n5. Create fixtures with edge cases like all NaN values, single row data, large time gaps",
        "priority": "high",
        "dependencies": [
          2
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 4,
        "title": "Implement Basic Metrics: Start Power and Target Power",
        "description": "Create the first two basic metrics that calculate baseline power consumption and extract target power settings for transition analysis.",
        "details": "In `src/metrics/basic_metrics.py`:\n```python\nimport pandas as pd\nimport numpy as np\nfrom typing import Dict, Any, Optional\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass BasicMetrics:\n    def __init__(self, df: pd.DataFrame, metadata: Dict[str, Any]):\n        self.df = df\n        self.metadata = metadata\n        self.action_index = metadata.get('action_index', 0)\n    \n    def calculate_start_power(self) -> Dict[str, Any]:\n        \"\"\"Metric 1: Calculate baseline power consumption before action.\"\"\"\n        pre_action_data = self.df[self.df['seconds'] < 0]\n        \n        if pre_action_data.empty:\n            logger.warning(\"No pre-action data available for start power calculation\")\n            return {\n                'median': None,\n                'last_value': None,\n                'difference': None,\n                'notes': 'No pre-action data available'\n            }\n        \n        # Filter valid (non-NaN) wattage values\n        valid_wattage = pre_action_data['summary_wattage'].dropna()\n        \n        if valid_wattage.empty:\n            return {\n                'median': None,\n                'last_value': None,\n                'difference': None,\n                'notes': 'All pre-action wattage values are NaN'\n            }\n        \n        # Calculate median\n        median_power = valid_wattage.median()\n        \n        # Get last value before action\n        last_idx = pre_action_data.index[-1]\n        last_value = pre_action_data.loc[last_idx, 'summary_wattage']\n        \n        # Calculate difference if last value is not NaN\n        if pd.notna(last_value):\n            difference = abs(last_value - median_power)\n            notes = 'Normal' if difference <= 50 else f'Significant difference: {difference:.1f}W'\n        else:\n            difference = None\n            notes = 'Last value before action is NaN'\n        \n        return {\n            'median': round(median_power, 2),\n            'last_value': round(last_value, 2) if pd.notna(last_value) else None,\n            'difference': round(difference, 2) if difference is not None else None,\n            'notes': notes,\n            'valid_samples': len(valid_wattage),\n            'total_samples': len(pre_action_data)\n        }\n    \n    def calculate_target_power(self) -> Dict[str, Any]:\n        \"\"\"Metric 2: Extract target power settings for transition analysis.\"\"\"\n        # Get mode power immediately before action\n        pre_action_data = self.df[self.df['seconds'] < 0]\n        post_action_data = self.df[self.df['seconds'] >= 0]\n        \n        if pre_action_data.empty:\n            before_power = None\n            logger.warning(\"No pre-action data for target power\")\n        else:\n            before_power = pre_action_data.iloc[-1]['mode_power']\n        \n        if post_action_data.empty:\n            after_power = None\n            logger.warning(\"No post-action data for target power\")\n        else:\n            after_power = post_action_data.iloc[0]['mode_power']\n        \n        # Calculate change\n        if before_power is not None and after_power is not None:\n            change = after_power - before_power\n            \n            # Validate target remains constant post-action\n            post_power_values = post_action_data['mode_power'].dropna()\n            if not post_power_values.empty:\n                is_constant = post_power_values.nunique() == 1\n                if not is_constant:\n                    logger.warning(\"Target power changes during post-action period\")\n                    notes = 'Target power not constant after action'\n                elif abs(change) < 1:\n                    notes = 'Warning: No significant change detected'\n                else:\n                    notes = 'Normal transition'\n            else:\n                notes = 'Cannot validate post-action consistency'\n        else:\n            change = None\n            notes = 'Missing data for calculation'\n        \n        return {\n            'before': round(before_power, 2) if before_power is not None else None,\n            'after': round(after_power, 2) if after_power is not None else None,\n            'change': round(change, 2) if change is not None else None,\n            'notes': notes\n        }\n```",
        "testStrategy": "Create unit tests in `tests/test_metrics/test_basic_metrics.py`:\n1. Test start power with normal data (consistent pre-action values)\n2. Test start power with high variance data\n3. Test start power with all NaN values\n4. Test target power with normal step change\n5. Test target power with no change (minimal step)\n6. Test target power with inconsistent post-action values\n7. Test edge cases: empty dataframes, single row data",
        "priority": "high",
        "dependencies": [
          3
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "Implement Step Direction and Temperature Metrics",
        "description": "Create step direction classification metric and temperature range analysis for thermal behavior during tests.",
        "details": "Continue in `src/metrics/basic_metrics.py`:\n```python\n    def calculate_step_direction(self, target_power_result: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Metric 3: Classify test type based on power transition.\"\"\"\n        # Requires target power metric results\n        if target_power_result['change'] is None:\n            return {\n                'direction': 'UNKNOWN',\n                'delta_watts': None,\n                'delta_percentage': None,\n                'notes': 'Cannot determine - missing target power data'\n            }\n        \n        change = target_power_result['change']\n        before = target_power_result['before']\n        \n        # Calculate percentage change\n        if before and before != 0:\n            pct_change = (change / before) * 100\n        else:\n            pct_change = 0\n        \n        # Apply classification thresholds\n        abs_change = abs(change)\n        abs_pct = abs(pct_change)\n        \n        if abs_change < 50 and abs_pct < 2:\n            direction = 'MINIMAL-STEP'\n        elif change > 0:\n            direction = 'UP-STEP'\n        else:\n            direction = 'DOWN-STEP'\n        \n        return {\n            'direction': direction,\n            'delta_watts': round(change, 2),\n            'delta_percentage': round(pct_change, 2),\n            'notes': f'{direction} detected with {abs_change:.0f}W change ({abs_pct:.1f}%)'\n        }\n    \n    def calculate_temperature_ranges(self) -> Dict[str, Any]:\n        \"\"\"Metric 4: Analyze thermal behavior during test.\"\"\"\n        pre_action = self.df[self.df['seconds'] < 0]\n        post_action = self.df[self.df['seconds'] >= 0]\n        \n        result = {\n            'pre_action': {},\n            'post_action': {},\n            'max_temperatures': {}\n        }\n        \n        # Analyze pre-action temperatures\n        if not pre_action.empty:\n            hash_temps_pre = pre_action['temp_hash_board_max'].dropna()\n            psu_temps_pre = pre_action['psu_temp_max'].dropna()\n            \n            if not hash_temps_pre.empty:\n                result['pre_action']['hash_board'] = {\n                    'min': round(hash_temps_pre.min(), 1),\n                    'max': round(hash_temps_pre.max(), 1),\n                    'mean': round(hash_temps_pre.mean(), 1),\n                    'std': round(hash_temps_pre.std(), 1)\n                }\n            \n            if not psu_temps_pre.empty:\n                result['pre_action']['psu'] = {\n                    'min': round(psu_temps_pre.min(), 1),\n                    'max': round(psu_temps_pre.max(), 1),\n                    'mean': round(psu_temps_pre.mean(), 1),\n                    'std': round(psu_temps_pre.std(), 1)\n                }\n        \n        # Analyze post-action temperatures\n        if not post_action.empty:\n            hash_temps_post = post_action['temp_hash_board_max'].dropna()\n            psu_temps_post = post_action['psu_temp_max'].dropna()\n            \n            if not hash_temps_post.empty:\n                result['post_action']['hash_board'] = {\n                    'min': round(hash_temps_post.min(), 1),\n                    'max': round(hash_temps_post.max(), 1),\n                    'mean': round(hash_temps_post.mean(), 1),\n                    'std': round(hash_temps_post.std(), 1)\n                }\n                \n                # Find max temperature timing\n                max_idx = post_action['temp_hash_board_max'].idxmax()\n                if pd.notna(max_idx):\n                    max_time = post_action.loc[max_idx, 'seconds']\n                    result['max_temperatures']['hash_board_time'] = round(max_time, 1)\n            \n            if not psu_temps_post.empty:\n                result['post_action']['psu'] = {\n                    'min': round(psu_temps_post.min(), 1),\n                    'max': round(psu_temps_post.max(), 1),\n                    'mean': round(psu_temps_post.mean(), 1),\n                    'std': round(psu_temps_post.std(), 1)\n                }\n                \n                # Find max PSU temperature timing\n                max_idx = post_action['psu_temp_max'].idxmax()\n                if pd.notna(max_idx):\n                    max_time = post_action.loc[max_idx, 'seconds']\n                    result['max_temperatures']['psu_time'] = round(max_time, 1)\n        \n        # Add temperature rise analysis\n        if result['pre_action'].get('hash_board') and result['post_action'].get('hash_board'):\n            temp_rise = result['post_action']['hash_board']['max'] - result['pre_action']['hash_board']['mean']\n            result['temperature_rise'] = round(temp_rise, 1)\n        \n        return result\n```",
        "testStrategy": "Extend tests in `tests/test_metrics/test_basic_metrics.py`:\n1. Test step direction for UP-STEP (>2% or >50W increase)\n2. Test step direction for DOWN-STEP (>2% or >50W decrease)\n3. Test step direction for MINIMAL-STEP (<2% and <50W)\n4. Test temperature ranges with complete data\n5. Test temperature ranges with missing temperature data\n6. Test temperature rise calculations\n7. Test max temperature timing identification",
        "priority": "high",
        "dependencies": [
          4
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Implement Time-Based Metrics: Band Entry and Setpoint Hit",
        "description": "Create metrics to measure time to reach target power band (±5%) and exact target power (±30W).",
        "details": "In `src/metrics/time_metrics.py`:\n```python\nimport pandas as pd\nimport numpy as np\nfrom typing import Dict, Any, Optional\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass TimeMetrics:\n    def __init__(self, df: pd.DataFrame, metadata: Dict[str, Any]):\n        self.df = df\n        self.metadata = metadata\n    \n    def calculate_band_entry(self, target_power_result: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Metric 5: Measure time to reach target power band (±5%).\"\"\"\n        target = target_power_result.get('after')\n        \n        if target is None:\n            return {\n                'time_seconds': None,\n                'achieved': False,\n                'notes': 'No target power available'\n            }\n        \n        # Define band boundaries (±5%)\n        lower_bound = target * 0.95\n        upper_bound = target * 1.05\n        \n        # Get post-action data\n        post_action = self.df[self.df['seconds'] >= 0].copy()\n        \n        if post_action.empty:\n            return {\n                'time_seconds': None,\n                'achieved': False,\n                'notes': 'No post-action data'\n            }\n        \n        # Find first entry into band\n        valid_wattage = post_action.dropna(subset=['summary_wattage'])\n        in_band = (valid_wattage['summary_wattage'] >= lower_bound) & \\\n                  (valid_wattage['summary_wattage'] <= upper_bound)\n        \n        if not in_band.any():\n            return {\n                'time_seconds': None,\n                'achieved': False,\n                'notes': f'Never reached band [{lower_bound:.0f}, {upper_bound:.0f}]W',\n                'band_lower': round(lower_bound, 2),\n                'band_upper': round(upper_bound, 2)\n            }\n        \n        # Implement consecutive sample validation (at least 3 consecutive samples)\n        consecutive_count = 0\n        entry_time = None\n        \n        for idx in valid_wattage.index:\n            if in_band.loc[idx]:\n                consecutive_count += 1\n                if consecutive_count >= 3:\n                    # Go back to first of the 3 consecutive samples\n                    entry_idx = valid_wattage.index[valid_wattage.index.get_loc(idx) - 2]\n                    entry_time = valid_wattage.loc[entry_idx, 'seconds']\n                    break\n            else:\n                consecutive_count = 0\n        \n        if entry_time is not None:\n            return {\n                'time_seconds': round(entry_time, 2),\n                'achieved': True,\n                'notes': f'Reached band at {entry_time:.1f}s',\n                'band_lower': round(lower_bound, 2),\n                'band_upper': round(upper_bound, 2)\n            }\n        else:\n            return {\n                'time_seconds': None,\n                'achieved': False,\n                'notes': 'Did not maintain band for 3 consecutive samples',\n                'band_lower': round(lower_bound, 2),\n                'band_upper': round(upper_bound, 2)\n            }\n    \n    def calculate_setpoint_hit(self, target_power_result: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Metric 6: Measure time to reach exact target power (±30W).\"\"\"\n        target = target_power_result.get('after')\n        \n        if target is None:\n            return {\n                'time_seconds': None,\n                'achieved': False,\n                'notes': 'No target power available'\n            }\n        \n        # Define proximity threshold (±30W)\n        threshold = 30\n        lower_bound = target - threshold\n        upper_bound = target + threshold\n        \n        # Get post-action data\n        post_action = self.df[self.df['seconds'] >= 0].copy()\n        \n        if post_action.empty:\n            return {\n                'time_seconds': None,\n                'achieved': False,\n                'notes': 'No post-action data'\n            }\n        \n        # Find first occurrence within threshold\n        valid_wattage = post_action.dropna(subset=['summary_wattage'])\n        within_threshold = (valid_wattage['summary_wattage'] >= lower_bound) & \\\n                          (valid_wattage['summary_wattage'] <= upper_bound)\n        \n        if not within_threshold.any():\n            # Find closest approach\n            distances = abs(valid_wattage['summary_wattage'] - target)\n            if not distances.empty:\n                min_distance = distances.min()\n                closest_idx = distances.idxmin()\n                closest_time = valid_wattage.loc[closest_idx, 'seconds']\n                \n                return {\n                    'time_seconds': None,\n                    'achieved': False,\n                    'notes': f'Never reached within ±{threshold}W. Closest: {min_distance:.1f}W at {closest_time:.1f}s',\n                    'closest_distance': round(min_distance, 2),\n                    'closest_time': round(closest_time, 2)\n                }\n            else:\n                return {\n                    'time_seconds': None,\n                    'achieved': False,\n                    'notes': 'No valid wattage data'\n                }\n        \n        # Get first occurrence\n        first_hit_idx = within_threshold.idxmax()\n        hit_time = valid_wattage.loc[first_hit_idx, 'seconds']\n        actual_power = valid_wattage.loc[first_hit_idx, 'summary_wattage']\n        \n        return {\n            'time_seconds': round(hit_time, 2),\n            'achieved': True,\n            'notes': f'Reached {actual_power:.0f}W at {hit_time:.1f}s',\n            'actual_power': round(actual_power, 2),\n            'distance_from_target': round(abs(actual_power - target), 2)\n        }\n```",
        "testStrategy": "Create tests in `tests/test_metrics/test_time_metrics.py`:\n1. Test band entry with quick achievement\n2. Test band entry with delayed achievement\n3. Test band entry never achieved\n4. Test band entry with intermittent values (consecutive sample validation)\n5. Test setpoint hit with exact match\n6. Test setpoint hit within threshold\n7. Test setpoint hit never achieved with closest approach tracking",
        "priority": "medium",
        "dependencies": [
          4
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Implement Stable Plateau and Anomaly Detection Metrics",
        "description": "Create stable plateau duration metric and implement sharp drops detection for power outages and significant drops.",
        "details": "Continue in `src/metrics/time_metrics.py` and create `src/metrics/anomaly_metrics.py`:\n\nIn `time_metrics.py`:\n```python\n    def calculate_stable_plateau(self, target_power_result: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Metric 7: Measure duration at stable target power.\"\"\"\n        target = target_power_result.get('after')\n        \n        if target is None:\n            return {\n                'duration_seconds': 0,\n                'start_time': None,\n                'end_time': None,\n                'achieved': False,\n                'notes': 'No target power available'\n            }\n        \n        # Define stability criteria (±2% for 30+ seconds)\n        tolerance = 0.02\n        min_duration = 30\n        lower_bound = target * (1 - tolerance)\n        upper_bound = target * (1 + tolerance)\n        \n        post_action = self.df[self.df['seconds'] >= 0].copy()\n        valid_data = post_action.dropna(subset=['summary_wattage'])\n        \n        if valid_data.empty:\n            return {\n                'duration_seconds': 0,\n                'start_time': None,\n                'end_time': None,\n                'achieved': False,\n                'notes': 'No valid post-action data'\n            }\n        \n        # Find longest stable segment\n        in_range = (valid_data['summary_wattage'] >= lower_bound) & \\\n                   (valid_data['summary_wattage'] <= upper_bound)\n        \n        longest_duration = 0\n        best_start = None\n        best_end = None\n        \n        # Scan for continuous segments\n        segment_start = None\n        for i in range(len(valid_data)):\n            idx = valid_data.index[i]\n            \n            if in_range.loc[idx]:\n                if segment_start is None:\n                    segment_start = valid_data.loc[idx, 'seconds']\n            else:\n                if segment_start is not None:\n                    segment_end = valid_data.iloc[i-1]['seconds']\n                    duration = segment_end - segment_start\n                    \n                    if duration > longest_duration:\n                        longest_duration = duration\n                        best_start = segment_start\n                        best_end = segment_end\n                    \n                    segment_start = None\n        \n        # Check if last segment is ongoing\n        if segment_start is not None:\n            segment_end = valid_data.iloc[-1]['seconds']\n            duration = segment_end - segment_start\n            \n            if duration > longest_duration:\n                longest_duration = duration\n                best_start = segment_start\n                best_end = segment_end\n        \n        achieved = longest_duration >= min_duration\n        \n        return {\n            'duration_seconds': round(longest_duration, 2),\n            'start_time': round(best_start, 2) if best_start is not None else None,\n            'end_time': round(best_end, 2) if best_end is not None else None,\n            'achieved': achieved,\n            'notes': f'Stable for {longest_duration:.1f}s' if achieved else f'Max stability: {longest_duration:.1f}s (< {min_duration}s required)',\n            'stability_band': [round(lower_bound, 2), round(upper_bound, 2)]\n        }\n```\n\nIn `src/metrics/anomaly_metrics.py`:\n```python\nimport pandas as pd\nimport numpy as np\nfrom typing import Dict, Any, List, Tuple\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass AnomalyMetrics:\n    def __init__(self, df: pd.DataFrame, metadata: Dict[str, Any]):\n        self.df = df\n        self.metadata = metadata\n    \n    def calculate_sharp_drops(self) -> Dict[str, Any]:\n        \"\"\"Metric 8: Detect power outages and significant drops.\"\"\"\n        # Thresholds\n        drop_threshold = 500  # Watts\n        time_window = 3  # seconds\n        \n        # Get post-action data\n        post_action = self.df[self.df['seconds'] >= 0].copy()\n        \n        drops = []\n        outage_periods = []\n        \n        # Detect drops in power\n        for i in range(1, len(post_action)):\n            curr_idx = post_action.index[i]\n            prev_idx = post_action.index[i-1]\n            \n            curr_power = post_action.loc[curr_idx, 'summary_wattage']\n            prev_power = post_action.loc[prev_idx, 'summary_wattage']\n            curr_time = post_action.loc[curr_idx, 'seconds']\n            prev_time = post_action.loc[prev_idx, 'seconds']\n            \n            # Check for outage flag\n            if post_action.loc[curr_idx, 'outage']:\n                if not outage_periods or curr_time - outage_periods[-1][1] > 1:\n                    outage_periods.append([curr_time, curr_time])\n                else:\n                    outage_periods[-1][1] = curr_time\n            \n            # Check for power drop\n            if pd.notna(curr_power) and pd.notna(prev_power):\n                time_diff = curr_time - prev_time\n                if time_diff <= time_window:\n                    power_drop = prev_power - curr_power\n                    if power_drop >= drop_threshold:\n                        drops.append({\n                            'time': round(curr_time, 2),\n                            'magnitude': round(power_drop, 2),\n                            'from_power': round(prev_power, 2),\n                            'to_power': round(curr_power, 2),\n                            'duration': round(time_diff, 2)\n                        })\n        \n        # Calculate total outage time\n        total_outage_time = sum(end - start for start, end in outage_periods)\n        \n        return {\n            'drop_count': len(drops),\n            'drops': drops[:5],  # Return up to 5 most significant\n            'outage_count': len(outage_periods),\n            'total_outage_seconds': round(total_outage_time, 2),\n            'outage_periods': [(round(s, 2), round(e, 2)) for s, e in outage_periods[:5]],\n            'notes': f'{len(drops)} drops detected, {len(outage_periods)} outage periods'\n        }\n```",
        "testStrategy": "Create comprehensive tests:\n1. Test stable plateau with long stable period\n2. Test stable plateau with multiple short periods\n3. Test stable plateau never achieved\n4. Test sharp drops detection with single drop\n5. Test sharp drops with multiple drops\n6. Test outage period detection\n7. Test combined drops and outages",
        "priority": "medium",
        "dependencies": [
          6
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Implement Spike Detection and Overshoot/Undershoot Metrics",
        "description": "Complete the anomaly detection metrics with spike detection for temporary power excursions and overshoot/undershoot analysis for transient response.",
        "details": "Continue in `src/metrics/anomaly_metrics.py`:\n```python\n    def calculate_spikes(self, start_power_result: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Metric 9: Detect temporary power excursions.\"\"\"\n        baseline = start_power_result.get('median')\n        \n        if baseline is None:\n            return {\n                'spike_count': 0,\n                'spikes': [],\n                'notes': 'No baseline power available'\n            }\n        \n        # Define spike thresholds (10% above/below baseline)\n        upper_threshold = baseline * 1.10\n        lower_threshold = baseline * 0.90\n        \n        # Use sliding window (3 samples)\n        window_size = 3\n        post_action = self.df[self.df['seconds'] >= 0].copy()\n        valid_data = post_action.dropna(subset=['summary_wattage'])\n        \n        spikes = []\n        \n        if len(valid_data) < window_size:\n            return {\n                'spike_count': 0,\n                'spikes': [],\n                'notes': 'Insufficient data for spike detection'\n            }\n        \n        # Sliding window detection\n        for i in range(len(valid_data) - window_size + 1):\n            window = valid_data.iloc[i:i+window_size]\n            window_mean = window['summary_wattage'].mean()\n            \n            # Check if middle point is a spike\n            mid_idx = window.index[1]\n            mid_power = window.loc[mid_idx, 'summary_wattage']\n            mid_time = window.loc[mid_idx, 'seconds']\n            \n            # Spike detection logic\n            if mid_power > upper_threshold or mid_power < lower_threshold:\n                # Verify it's temporary (surrounding values are closer to baseline)\n                first_power = window.iloc[0]['summary_wattage']\n                last_power = window.iloc[2]['summary_wattage']\n                \n                first_closer = abs(first_power - baseline) < abs(mid_power - baseline)\n                last_closer = abs(last_power - baseline) < abs(mid_power - baseline)\n                \n                if first_closer and last_closer:\n                    spike_type = 'up' if mid_power > baseline else 'down'\n                    spikes.append({\n                        'time': round(mid_time, 2),\n                        'power': round(mid_power, 2),\n                        'deviation': round(mid_power - baseline, 2),\n                        'deviation_pct': round((mid_power - baseline) / baseline * 100, 2),\n                        'type': spike_type\n                    })\n        \n        # Remove duplicate spikes (within 2 seconds)\n        filtered_spikes = []\n        for spike in spikes:\n            if not filtered_spikes or spike['time'] - filtered_spikes[-1]['time'] > 2:\n                filtered_spikes.append(spike)\n        \n        return {\n            'spike_count': len(filtered_spikes),\n            'spikes': filtered_spikes[:10],  # Return up to 10 spikes\n            'baseline_power': round(baseline, 2),\n            'thresholds': {\n                'upper': round(upper_threshold, 2),\n                'lower': round(lower_threshold, 2)\n            },\n            'notes': f'{len(filtered_spikes)} spikes detected'\n        }\n    \n    def calculate_overshoot_undershoot(self, target_power_result: Dict[str, Any], \n                                       step_direction_result: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Metric 10: Analyze transient response characteristics.\"\"\"\n        target = target_power_result.get('after')\n        direction = step_direction_result.get('direction')\n        \n        if target is None or direction == 'UNKNOWN':\n            return {\n                'detected': False,\n                'type': None,\n                'magnitude': None,\n                'time': None,\n                'duration': None,\n                'notes': 'Missing required data'\n            }\n        \n        # Dynamic thresholds (4% or 200W, whichever is larger)\n        pct_threshold = target * 0.04\n        abs_threshold = 200\n        threshold = max(pct_threshold, abs_threshold)\n        \n        post_action = self.df[self.df['seconds'] >= 0].copy()\n        valid_data = post_action.dropna(subset=['summary_wattage'])\n        \n        if valid_data.empty:\n            return {\n                'detected': False,\n                'type': None,\n                'magnitude': None,\n                'time': None,\n                'duration': None,\n                'notes': 'No valid post-action data'\n            }\n        \n        # Detect based on step direction\n        if direction == 'UP-STEP':\n            # Look for overshoot (power > target + threshold)\n            overshoot_mask = valid_data['summary_wattage'] > (target + threshold)\n            if overshoot_mask.any():\n                # Find maximum overshoot\n                max_idx = valid_data.loc[overshoot_mask, 'summary_wattage'].idxmax()\n                max_power = valid_data.loc[max_idx, 'summary_wattage']\n                max_time = valid_data.loc[max_idx, 'seconds']\n                \n                # Calculate duration (how long above threshold)\n                duration = 0\n                for idx in valid_data.index:\n                    if valid_data.loc[idx, 'summary_wattage'] > (target + threshold):\n                        duration += 1\n                    elif idx > max_idx:\n                        break\n                \n                return {\n                    'detected': True,\n                    'type': 'overshoot',\n                    'magnitude': round(max_power - target, 2),\n                    'magnitude_pct': round((max_power - target) / target * 100, 2),\n                    'time': round(max_time, 2),\n                    'duration': duration,\n                    'peak_power': round(max_power, 2),\n                    'threshold': round(target + threshold, 2),\n                    'notes': f'Overshoot of {max_power - target:.0f}W at {max_time:.1f}s'\n                }\n        \n        elif direction == 'DOWN-STEP':\n            # Look for undershoot (power < target - threshold)\n            undershoot_mask = valid_data['summary_wattage'] < (target - threshold)\n            if undershoot_mask.any():\n                # Find minimum undershoot\n                min_idx = valid_data.loc[undershoot_mask, 'summary_wattage'].idxmin()\n                min_power = valid_data.loc[min_idx, 'summary_wattage']\n                min_time = valid_data.loc[min_idx, 'seconds']\n                \n                # Calculate duration\n                duration = 0\n                for idx in valid_data.index:\n                    if valid_data.loc[idx, 'summary_wattage'] < (target - threshold):\n                        duration += 1\n                    elif idx > min_idx:\n                        break\n                \n                return {\n                    'detected': True,\n                    'type': 'undershoot',\n                    'magnitude': round(target - min_power, 2),\n                    'magnitude_pct': round((target - min_power) / target * 100, 2),\n                    'time': round(min_time, 2),\n                    'duration': duration,\n                    'trough_power': round(min_power, 2),\n                    'threshold': round(target - threshold, 2),\n                    'notes': f'Undershoot of {target - min_power:.0f}W at {min_time:.1f}s'\n                }\n        \n        return {\n            'detected': False,\n            'type': None,\n            'magnitude': None,\n            'time': None,\n            'duration': None,\n            'notes': f'No transient detected for {direction}'\n        }\n```",
        "testStrategy": "Complete anomaly metric tests:\n1. Test spike detection with clear up/down spikes\n2. Test spike filtering (removing duplicates)\n3. Test spike detection with noisy data\n4. Test overshoot detection for UP-STEP\n5. Test undershoot detection for DOWN-STEP\n6. Test no transient detection for MINIMAL-STEP\n7. Test magnitude and duration calculations",
        "priority": "medium",
        "dependencies": [
          7
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Create Metric Orchestrator and Dependency Management",
        "description": "Build a central orchestrator that manages metric calculation order based on dependencies and aggregates all results.",
        "details": "Create `src/metrics/orchestrator.py`:\n```python\nimport pandas as pd\nfrom typing import Dict, Any, List\nimport logging\nfrom datetime import datetime\n\nfrom src.data_processing.ingestion import DataIngestion\nfrom src.data_processing.preprocessing import DataPreprocessor\nfrom src.metrics.basic_metrics import BasicMetrics\nfrom src.metrics.time_metrics import TimeMetrics\nfrom src.metrics.anomaly_metrics import AnomalyMetrics\n\nlogger = logging.getLogger(__name__)\n\nclass MetricOrchestrator:\n    \"\"\"Orchestrates metric calculation with dependency management.\"\"\"\n    \n    def __init__(self):\n        self.results = {}\n        self.metadata = {}\n        self.execution_order = [\n            'preprocessing',\n            'start_power',\n            'target_power',\n            'step_direction',\n            'temperature_ranges',\n            'band_entry',\n            'setpoint_hit',\n            'stable_plateau',\n            'sharp_drops',\n            'spikes',\n            'overshoot_undershoot'\n        ]\n    \n    def process_file(self, filepath: str) -> Dict[str, Any]:\n        \"\"\"Process CSV file and calculate all metrics.\"\"\"\n        start_time = datetime.now()\n        \n        try:\n            # Data ingestion\n            logger.info(f\"Loading file: {filepath}\")\n            ingestion = DataIngestion()\n            df = ingestion.load_csv(filepath)\n            \n            # Preprocessing\n            logger.info(\"Preprocessing data\")\n            preprocessor = DataPreprocessor(df)\n            processed_df, preprocessing_metadata = preprocessor.preprocess()\n            \n            self.metadata.update(preprocessing_metadata)\n            self.metadata['filename'] = filepath\n            self.metadata['total_rows'] = len(processed_df)\n            \n            # Initialize metric calculators\n            basic_metrics = BasicMetrics(processed_df, self.metadata)\n            time_metrics = TimeMetrics(processed_df, self.metadata)\n            anomaly_metrics = AnomalyMetrics(processed_df, self.metadata)\n            \n            # Calculate metrics in dependency order\n            logger.info(\"Calculating metrics\")\n            \n            # Basic metrics\n            self.results['start_power'] = basic_metrics.calculate_start_power()\n            self.results['target_power'] = basic_metrics.calculate_target_power()\n            \n            # Step direction (depends on target_power)\n            self.results['step_direction'] = basic_metrics.calculate_step_direction(\n                self.results['target_power']\n            )\n            \n            # Temperature (independent)\n            self.results['temperature_ranges'] = basic_metrics.calculate_temperature_ranges()\n            \n            # Time-based metrics (depend on target_power)\n            self.results['band_entry'] = time_metrics.calculate_band_entry(\n                self.results['target_power']\n            )\n            self.results['setpoint_hit'] = time_metrics.calculate_setpoint_hit(\n                self.results['target_power']\n            )\n            self.results['stable_plateau'] = time_metrics.calculate_stable_plateau(\n                self.results['target_power']\n            )\n            \n            # Anomaly metrics\n            self.results['sharp_drops'] = anomaly_metrics.calculate_sharp_drops()\n            self.results['spikes'] = anomaly_metrics.calculate_spikes(\n                self.results['start_power']\n            )\n            self.results['overshoot_undershoot'] = anomaly_metrics.calculate_overshoot_undershoot(\n                self.results['target_power'],\n                self.results['step_direction']\n            )\n            \n            # Calculate processing time\n            end_time = datetime.now()\n            processing_time = (end_time - start_time).total_seconds()\n            \n            # Compile final results\n            return {\n                'success': True,\n                'metrics': self.results,\n                'metadata': {\n                    **self.metadata,\n                    'processing_time_seconds': round(processing_time, 3),\n                    'timestamp': datetime.now().isoformat()\n                },\n                'raw_data': processed_df.to_dict('records')  # For visualization\n            }\n            \n        except Exception as e:\n            logger.error(f\"Error processing file: {e}\", exc_info=True)\n            return {\n                'success': False,\n                'error': str(e),\n                'error_type': type(e).__name__,\n                'metadata': self.metadata\n            }\n    \n    def validate_results(self) -> Dict[str, List[str]]:\n        \"\"\"Validate calculated metrics for consistency.\"\"\"\n        warnings = []\n        errors = []\n        \n        # Check if all expected metrics were calculated\n        expected_metrics = self.execution_order[1:]  # Exclude preprocessing\n        for metric in expected_metrics:\n            if metric not in self.results:\n                errors.append(f\"Missing metric: {metric}\")\n        \n        # Validate metric relationships\n        if 'start_power' in self.results and 'target_power' in self.results:\n            start = self.results['start_power'].get('median')\n            target_before = self.results['target_power'].get('before')\n            \n            if start and target_before and abs(start - target_before) > 100:\n                warnings.append(\n                    f\"Large discrepancy between start power ({start:.0f}W) \"\n                    f\"and target before ({target_before:.0f}W)\"\n                )\n        \n        # Check time metric consistency\n        if 'band_entry' in self.results and 'setpoint_hit' in self.results:\n            band_time = self.results['band_entry'].get('time_seconds')\n            setpoint_time = self.results['setpoint_hit'].get('time_seconds')\n            \n            if band_time and setpoint_time and setpoint_time < band_time:\n                warnings.append(\n                    f\"Setpoint hit ({setpoint_time}s) before band entry ({band_time}s)\"\n                )\n        \n        return {\n            'warnings': warnings,\n            'errors': errors,\n            'valid': len(errors) == 0\n        }\n```",
        "testStrategy": "Create integration tests in `tests/test_metrics/test_orchestrator.py`:\n1. Test full pipeline with clean data\n2. Test dependency resolution\n3. Test error handling for bad files\n4. Test result validation\n5. Test processing time measurement\n6. Create sample CSV files representing different test scenarios\n7. Verify all metrics are calculated in correct order",
        "priority": "high",
        "dependencies": [
          8
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "Implement Comprehensive Testing Framework",
        "description": "Create a complete testing framework with unit tests for all metrics, integration tests for the orchestrator, and test fixtures with sample data.",
        "details": "Create test fixtures in `tests/fixtures/`:\n\n`tests/fixtures/sample_data.py`:\n```python\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\n\ndef create_upstep_test_data():\n    \"\"\"Create sample data for UP-STEP test.\"\"\"\n    # Pre-action: stable at 2000W\n    pre_times = np.arange(-300, 0, 1)\n    pre_power = np.random.normal(2000, 10, len(pre_times))\n    pre_mode = np.full(len(pre_times), 2000)\n    \n    # Post-action: step to 3000W with overshoot\n    post_times = np.arange(0, 600, 1)\n    post_power = np.zeros(len(post_times))\n    \n    # Transient response\n    for i, t in enumerate(post_times):\n        if t < 10:\n            post_power[i] = 2000 + (3000-2000) * (t/10)\n        elif t < 20:\n            post_power[i] = 3000 + 200 * np.exp(-(t-10)/5)  # Overshoot\n        else:\n            post_power[i] = np.random.normal(3000, 15, 1)[0]\n    \n    post_mode = np.full(len(post_times), 3000)\n    \n    # Combine data\n    df = pd.DataFrame({\n        'miner.seconds': np.concatenate([pre_times, post_times]),\n        'miner.mode.power': np.concatenate([pre_mode, post_mode]),\n        'miner.summary.wattage': np.concatenate([pre_power, post_power]),\n        'miner.temp.hash_board_max': np.random.normal(65, 2, len(pre_times) + len(post_times)),\n        'miner.psu.temp_max': np.random.normal(55, 2, len(pre_times) + len(post_times)),\n        'miner.outage': np.zeros(len(pre_times) + len(post_times), dtype=bool)\n    })\n    \n    return df\n\ndef create_downstep_with_drops_data():\n    \"\"\"Create sample data for DOWN-STEP with power drops.\"\"\"\n    # Similar structure but with drops\n    df = create_upstep_test_data()\n    df['miner.mode.power'] = df['miner.mode.power'].apply(lambda x: 3000 if x == 2000 else 2000)\n    df['miner.summary.wattage'] = 5000 - df['miner.summary.wattage']  # Invert\n    \n    # Add some drops\n    drop_indices = [350, 450, 550]\n    for idx in drop_indices:\n        if idx < len(df):\n            df.loc[idx:idx+5, 'miner.summary.wattage'] = 0\n            df.loc[idx:idx+5, 'miner.outage'] = True\n    \n    return df\n\ndef save_test_fixtures():\n    \"\"\"Save test CSV files.\"\"\"\n    fixtures_dir = Path(__file__).parent\n    \n    # Save different test scenarios\n    scenarios = {\n        'upstep_clean.csv': create_upstep_test_data(),\n        'downstep_with_drops.csv': create_downstep_with_drops_data(),\n    }\n    \n    for filename, df in scenarios.items():\n        df.to_csv(fixtures_dir / filename, index=False)\n```\n\nCreate `tests/conftest.py` for pytest fixtures:\n```python\nimport pytest\nimport pandas as pd\nfrom pathlib import Path\n\n@pytest.fixture\ndef sample_upstep_df():\n    \"\"\"Provide sample UP-STEP dataframe.\"\"\"\n    from tests.fixtures.sample_data import create_upstep_test_data\n    return create_upstep_test_data()\n\n@pytest.fixture\ndef sample_downstep_df():\n    \"\"\"Provide sample DOWN-STEP dataframe.\"\"\"\n    from tests.fixtures.sample_data import create_downstep_with_drops_data\n    return create_downstep_with_drops_data()\n\n@pytest.fixture\ndef temp_csv_file(tmp_path, sample_upstep_df):\n    \"\"\"Create temporary CSV file for testing.\"\"\"\n    csv_path = tmp_path / \"test_data.csv\"\n    sample_upstep_df.to_csv(csv_path, index=False)\n    return str(csv_path)\n```\n\nCreate comprehensive test example `tests/test_metrics/test_basic_metrics.py`:\n```python\nimport pytest\nimport pandas as pd\nimport numpy as np\nfrom src.metrics.basic_metrics import BasicMetrics\n\nclass TestStartPower:\n    def test_normal_calculation(self, sample_upstep_df):\n        \"\"\"Test start power with normal data.\"\"\"\n        metrics = BasicMetrics(sample_upstep_df, {'action_index': 300})\n        result = metrics.calculate_start_power()\n        \n        assert result['median'] is not None\n        assert 1990 < result['median'] < 2010  # Should be close to 2000W\n        assert result['achieved'] is True\n        assert 'valid_samples' in result\n    \n    def test_no_pre_action_data(self):\n        \"\"\"Test when no pre-action data exists.\"\"\"\n        df = pd.DataFrame({\n            'seconds': [0, 1, 2],\n            'summary_wattage': [1000, 1000, 1000],\n            'mode_power': [1000, 1000, 1000]\n        })\n        metrics = BasicMetrics(df, {'action_index': 0})\n        result = metrics.calculate_start_power()\n        \n        assert result['median'] is None\n        assert result['notes'] == 'No pre-action data available'\n    \n    def test_all_nan_values(self):\n        \"\"\"Test when all pre-action values are NaN.\"\"\"\n        df = pd.DataFrame({\n            'seconds': [-3, -2, -1, 0, 1],\n            'summary_wattage': [np.nan, np.nan, np.nan, 1000, 1000],\n            'mode_power': [1000, 1000, 1000, 1000, 1000]\n        })\n        metrics = BasicMetrics(df, {'action_index': 3})\n        result = metrics.calculate_start_power()\n        \n        assert result['median'] is None\n        assert 'All pre-action wattage values are NaN' in result['notes']\n```\n\nCreate `tests/test_integration.py`:\n```python\nimport pytest\nfrom src.metrics.orchestrator import MetricOrchestrator\n\ndef test_full_pipeline(temp_csv_file):\n    \"\"\"Test complete metric calculation pipeline.\"\"\"\n    orchestrator = MetricOrchestrator()\n    result = orchestrator.process_file(temp_csv_file)\n    \n    assert result['success'] is True\n    assert 'metrics' in result\n    assert 'metadata' in result\n    \n    # Verify all metrics calculated\n    expected_metrics = [\n        'start_power', 'target_power', 'step_direction',\n        'temperature_ranges', 'band_entry', 'setpoint_hit',\n        'stable_plateau', 'sharp_drops', 'spikes',\n        'overshoot_undershoot'\n    ]\n    \n    for metric in expected_metrics:\n        assert metric in result['metrics']\n    \n    # Validate processing time\n    assert result['metadata']['processing_time_seconds'] < 1.0\n```",
        "testStrategy": "Run comprehensive test suite:\n1. Execute `pytest -v` to run all tests\n2. Use `pytest --cov=src` for coverage report\n3. Target >90% code coverage\n4. Run `pytest -k test_metric_name` for specific metric tests\n5. Use `pytest --lf` to rerun failed tests\n6. Create GitHub Actions workflow for CI/CD\n7. Add performance benchmarks with pytest-benchmark",
        "priority": "high",
        "dependencies": [
          9
        ],
        "status": "pending",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-11-05T22:33:05.499Z",
      "updated": "2025-11-05T22:33:05.499Z",
      "description": "Tasks for master context"
    }
  }
}