# Task ID: 11
# Title: Comprehensive Real Data Validation Testing Framework
# Status: done
# Dependencies: 9, 10
# Priority: high
# Description: Create a comprehensive validation testing framework that processes 20+ real CSV files from tests/fixtures/real_data/ directory and generates detailed validation reports to identify and fix any data processing issues.
# Details:
Create `scripts/validate_real_data_comprehensive.py` that:

1. **File Discovery and Organization**: Scan `tests/fixtures/real_data/` directory for all CSV files, categorize by naming patterns, and create processing batches.

2. **Comprehensive Processing Pipeline**: For each file, execute the full MetricOrchestrator pipeline:
   - Data ingestion with validation
   - Preprocessing with metadata extraction
   - All 10 metric calculations in dependency order
   - Result validation and consistency checks

3. **Detailed Reporting System**: Generate JSON and HTML reports containing:
   - Per-file processing results with success/failure status
   - Timing metrics for performance analysis
   - Data quality assessments (missing values, outliers, anomalies)
   - Metric calculation results summary
   - Error categorization and stack traces
   - Statistical analysis across all files

4. **Error Analysis and Fix Recommendations**: 
   - Categorize errors by type (ingestion, preprocessing, metric calculation)
   - Identify common failure patterns across files
   - Generate specific fix recommendations for each error type
   - Create a priority-ranked list of issues to address

5. **Performance Benchmarking**: Track processing times, memory usage, and identify bottlenecks for optimization.

6. **Data Quality Metrics**: Calculate data completeness, consistency scores, and identify files needing manual review.

7. **Automated Issue Detection**: Implement checks for common data issues like missing action points, corrupted timestamps, invalid power values, and temperature sensor failures.

The script should handle all edge cases gracefully, provide progress indicators for long-running operations, and create both machine-readable (JSON) and human-readable (HTML) output formats. Include command-line options for selective processing, verbose output, and report customization.

# Test Strategy:
1. Prepare test environment by placing 20+ diverse real CSV files in `tests/fixtures/real_data/` directory
2. Run the validation script: `python scripts/validate_real_data_comprehensive.py`
3. Verify all files are processed without script crashes
4. Review generated reports in `validation_reports/` directory for completeness
5. Validate JSON report structure matches expected schema
6. Check HTML report renders correctly with all sections present
7. Verify error categorization is accurate and actionable
8. Test selective processing with `--filter` and `--limit` options
9. Measure processing performance and memory usage
10. Confirm all identified issues have specific fix recommendations
11. Run script multiple times to ensure consistent results
12. Validate that fixed issues no longer appear in subsequent runs
13. Test with various file sizes and corruption scenarios
14. Verify progress indicators work correctly for long operations
